# !/usr/bin/env python

import sys
sys.path.insert(1, "/home/ross/EuPathGalaxy/Tools/lib/python/")
#sys.path.insert(0, "/opt/galaxy/tools/eupath/Tools/lib/python")
from eupath import NewEupathExporter, ReferenceGenome
import optparse
import sys
import re
from subprocess import check_output, call

"""
python EuPathGalaxy/Tools/bin/exportSNPDataToEuPathDB TestSetDataName DataSetSummary DataSetDescription ross.madden.333934643@eupathdb.org /home/ross/EuPathGalaxy/Tools/lib/python exportToEuPathDBInfo.html /scratch/galaxy/files/016/dataset_16005.dat  SampleFileName

python EuPathGalaxy/Tools/bin/NewexportSNPDataToEuPathDB TestSetDataName DataSetSummary DataSetDescription ross.madden.333934644@eupathdb.org /home/ross/EuPathGalaxy/Tools/lib/python exportToEuPathDBInfo.html /scratch/galaxy/files/016/dataset_16005.dat  SampleFileName TriTrypDB-39_TbruceiTREU927_Genome



args = "$dataset_name" 
    "$summary" 
    "$description"
    "$__user_email__" 
    "$__tool_directory__" 
    "$output" 
"""


def main():

    parser = optparse.OptionParser()
    (options, args) = parser.parse_args()   

    # for i in args:
    #     print >> sys.stdout, i 
    # print >> sys.stdout, file_name    

    # So users are greeted with a bewildering traceback
    sys.tracebacklimit = 0

    # This class/function can be made in a new file where the file handler below can be created. 
    # maybe in Tools/bin/exportSNPDataToEuPathDB
    class FileValidator():

        def __init__(self):
            self.temp = ''

        def validate(self, file_to_val):

            print >> sys.stdout, "File to validate: ", file_to_val
            print >> sys.stdout, "---At validate. Beep boop.---"

            with open(file_to_val, mode='r') as file:

                bad_lines = []

                for line in file: 
                    #while i < 1000:
                    #line = next(file)                    
                    #print unicode(line[0:100], 'utf-8')
                    #if re.match(r"^.*\t\d*\t.*\t[ATGC]*\t[ATGC]*\t(\d*\.\d*|\d*)\t(\w*|\.)\t.*$", line):
                    if re.match(r"^.*\t\d*\t.*\t((([ATGCN]*),){1,}([ATGCN]*)|([ATGCN]*))\t((([ATGCN]*),){1,}([ATGCN]*)|([ATGCN]*))\t((\d*.\d*e-\d*)|(\d*\.\d*)|(\d*))\t(\w*|\.)\t.*$", line):
                        # This is attempting to match a line in the file where the data is stored. It assumes that the data is
                        # in the same order as above. Looking for string, tab, number, tab, sting, tab, ATC or G, tab ATC or G, tab
                        # int/float, tab
                        #print "-----", line
                        #print "Line ", i, " ok." 
                        pass
                    
                    elif unicode(line[0:2], 'utf-8') == '##':
                        # This is to ignore the headers that are added to the file, Jbrowse only cares about certain col headers
                        # and the data. VCFTools vcf-validator was too rigid to work here, kept failing due to the header being
                        # incorrect (even though the data looked like it was formatted correctly.)
                        pass

                    elif re.match(r"^#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\t.*$", line):
                        #elif '#CHROM' in line:
                        # This is testing for the header of the data. Note the wildcard at the end that will match any additions 
                        # by other programs that are not using the usual cols. 
                        # The order should not be an issue as it seems to be rigid.         
                        #print "-----", line
                        pass
                        
                    else:
                        bad_lines.append(line)

                if len(bad_lines) > 0:    
                    print >> sys.stderr,  "###### Error: Can't validate the file. ######"
                    print >> sys.stderr, "Hint: Is the data header formmatted: #CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT ?????"
                    print >> sys.stderr,  "###### These lines are not in the correct format for Jbrowse to read the data. ######"
                    for bad in bad_lines:            
                        print >> sys.stderr,  bad
                    raise ValueError(bad_lines)

                    # Redundancy.
                    sys.exit(1)

                elif len(bad_lines) == 0:
                    print >> sys.stderr, "File looks ok."                  
                    
                # raise ValueError('All broken!')



    class VCFFileHandler(NewEupathExporter.BaseFileHandler):
        """
        A class for handling the export of VCF file.
        The FileCollector and the Exporter can be overwritten if needed. 
        The validator should be bespoke to a file type - this runs on intilization for this class. .
        """

        # Constants
        TYPE = "VCFFile"
        VERSION = "1.0"        

        def __init__(self, validator):

            self.parse_params(args)
            print >> sys.stderr, 'Other params:', self._other_params 
	    print >> sys.stderr, "Genome", self._other_params[3]
	    
            
	    NewEupathExporter.BaseFileHandler.__init__(self, 
            VCFFileHandler.TYPE, 
            VCFFileHandler.VERSION,
            NewEupathExporter.FileCollector(self._other_params[0], self._other_params[1]),
            NewEupathExporter.Exporter(self._tool_directory, self.TYPE, self.VERSION, self._user_id, self._dataset_name, self._summary, self._description),
            validator,
	    self._other_params[3],
            args
            )
        
            try:
                self.validation(self._other_params[0])
            except:
                raise Exception("Validation failed.")
		

        def test(self):
            # Works
            print >> sys.stdout, "_tool_directory:", self._exporter._tool_directory
            # print >> sys.stdout, "_tool_directory:", self._exporter.collect_rest_data()
            print >> sys.stdout, "_dataset_name:", self._dataset_name  
	    print >> sys.stderr, self.identify_dependencies()
	    print >> sys.stderr, self.identify_projects()
            # Testing

            # print >> sys.stdout, "_datasetInfos:", self._filecollector._datasetInfos  
             
        def validation(self, file):
                print >> sys.stdout, "--- Try validation. ---"
                self._validator.validate(file)
                print >> sys.stdout, "--- Validation success. ---" 

        def index_and_zip(self):
            """
            If the validation is succesful this overwites the _datasetInfos with the path of the zipped and indexed file.
            This is then used for the export and the original file is left for Galaxy uses.
            """
            print >> sys.stdout, "--- Zip and index .---", self._other_params[0]
           
            # Getting only the file name.
            rev_file = str(self._other_params[0])
            rev_file = rev_file.split('/')[-1]

            print >> sys.stderr, 'Rev_file', rev_file
            # # do bgzip op on temp.
            # # original file is still in place. 

            tmp_file = '/tmp/' + rev_file
            print >> sys.stderr, tmp_file

            # Copy to /tmp/galaxy. Zip and index. 
            # Must be a better way to reference samtools - tabix and bgzip. - Works as is though.
            print >> sys.stderr, 'Copy to /tmp'
            call(['cp', self._other_params[0], tmp_file])
            print >> sys.stderr, 'Zipping....'
            call(['/mnt/galaxyTools/tools/tabix/0.2.6/bgzip', '-f', tmp_file])
            print >> sys.stderr, 'Indexing....'
            call(['/mnt/galaxyTools/tools/tabix/0.2.6/tabix', '-pf', 'vcf', tmp_file + '.gz']) # .tbi also after this.

            # New file path is updated in the _datasetInfos attribute. 
            file_to_export = tmp_file + '.gz' + '.tbi' 
            self._filecollector._datasetInfos[0]['path'] = file_to_export

            return self._filecollector._datasetInfos

        def identify_dataset_files(self):
            """This must return as list formatted as BaseFileHandler.identify_dataset_files() states."""

            # Note that index_and_zip is updating self._filecollector._datasetInfos[0]['path']
            return self.index_and_zip()
    

	def identify_dependencies(self):
	    """
       	    The appropriate dependency(ies) will be determined by the reference genome selected - only one for now. Ross - this could be moved into the parent class if it never changes
            """
            return [{
            	"resourceIdentifier": self._refGenome.identifier,
            	"resourceVersion": self._refGenome.version,
            	"resourceDisplayName": self._refGenome.display_name
        	}]

    	def identify_projects(self):
        	return [self._refGenome.project]


    # Makes a FileHandler class composed of the validator.
    validator_class = FileValidator()
    worker = VCFFileHandler(validator_class)

    # Runs the export. 
    #worker._exporter.export(worker.identify_dataset_files())
    worker.test()

if __name__ == "__main__":
    sys.exit(main())
